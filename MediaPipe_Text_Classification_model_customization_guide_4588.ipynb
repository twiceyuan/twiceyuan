{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EJt5T80U6Oq-"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSlqybAM6Si0",
        "outputId": "4c88d17a-ca1e-487f-aea5-1a4b58480e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from mediapipe_model_maker import text_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHUV3gac6UqV",
        "outputId": "61ca0b59-76c3-4340-9a67-f2d003e52b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/twiceyuan/twiceyuan/raw/main/reproduce_4588.zip?t=1asdasdas1\n",
            "18519/18519 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "data_path = tf.keras.utils.get_file(\n",
        "    fname='reproduce_4588.zip',\n",
        "    origin='https://github.com/twiceyuan/twiceyuan/raw/main/reproduce_4588.zip',\n",
        "    extract=True)\n",
        "data_dir = os.path.join(os.path.dirname(data_path), 'reproduce_4588')  # folder name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W4scRyme7Eld"
      },
      "outputs": [],
      "source": [
        "csv_params = text_classifier.CSVParams(\n",
        "    text_column='sentence', label_column='label', delimiter=',')\n",
        "train_data = text_classifier.Dataset.from_csv(\n",
        "    filename=os.path.join(os.path.join(data_dir, 'train.csv')),\n",
        "    csv_params=csv_params)\n",
        "validation_data = text_classifier.Dataset.from_csv(\n",
        "    filename=os.path.join(os.path.join(data_dir, 'dev.csv')),\n",
        "    csv_params=csv_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DURwRB-F7GHG"
      },
      "outputs": [],
      "source": [
        "supported_model = text_classifier.SupportedModels.AVERAGE_WORD_EMBEDDING_CLASSIFIER\n",
        "hparams = text_classifier.HParams(epochs=10, batch_size=32, learning_rate=1, export_dir=\"awe_exported_models\")\n",
        "options = text_classifier.TextClassifierOptions(supported_model=supported_model, hparams=hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loE1PUWz7L1Q",
        "outputId": "dba5b651-7625-4525-ad0f-509a62f880f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 8s 118ms/step - loss: 1.3869 - accuracy: 0.2531 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.3859 - accuracy: 0.2719 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3860 - accuracy: 0.2531 - val_loss: 1.3870 - val_accuracy: 0.2583\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.3858 - accuracy: 0.2646 - val_loss: 1.3868 - val_accuracy: 0.2208\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3853 - accuracy: 0.2667 - val_loss: 1.3867 - val_accuracy: 0.2208\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3846 - accuracy: 0.2646 - val_loss: 1.3866 - val_accuracy: 0.2208\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.3849 - accuracy: 0.2688 - val_loss: 1.3861 - val_accuracy: 0.2208\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3848 - accuracy: 0.2479 - val_loss: 1.3857 - val_accuracy: 0.2208\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.3843 - accuracy: 0.2562 - val_loss: 1.3844 - val_accuracy: 0.2208\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3835 - accuracy: 0.2562 - val_loss: 1.3837 - val_accuracy: 0.2208\n"
          ]
        }
      ],
      "source": [
        "model = text_classifier.TextClassifier.create(train_data, validation_data, options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoOYKbvo8HAP",
        "outputId": "89962bb9-b9e5-4b95-a56a-d2312c1f6a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3837 - accuracy: 0.2208\n",
            "Test loss:1.3837242126464844, Test accuracy:0.22083333134651184\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(validation_data)\n",
        "print(f'Test loss:{loss}, Test accuracy:{acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yce3tZtl8PT3"
      },
      "outputs": [],
      "source": [
        "model.export_model()\n",
        "model.export_labels(export_dir=options.hparams.export_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2LpqDHtm8eJn"
      },
      "outputs": [],
      "source": [
        "supported_model = text_classifier.SupportedModels.MOBILEBERT_CLASSIFIER\n",
        "hparams = text_classifier.HParams(epochs=10, batch_size=48, learning_rate=3e-5, export_dir=\"bert_exported_models\")\n",
        "options = text_classifier.TextClassifierOptions(supported_model=supported_model, hparams=hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbruWWmB8h-v",
        "outputId": "b8f222b0-eedd-4507-e25d-980be3f820a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/text_classifier/mobilebert_tiny\n",
            "Using existing files at /tmp/model_maker/text_classifier/mobilebert_tiny\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 202s 665ms/step - loss: 13999.6689 - test_accuracy: 0.2562 - val_loss: 170.0739 - val_test_accuracy: 0.2333\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 8s 400ms/step - loss: 202.6890 - test_accuracy: 0.2448 - val_loss: 1.4850 - val_test_accuracy: 0.2833\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 9s 429ms/step - loss: 1.6946 - test_accuracy: 0.5719 - val_loss: 0.4492 - val_test_accuracy: 0.9625\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 9s 432ms/step - loss: 0.2046 - test_accuracy: 0.9635 - val_loss: 0.0205 - val_test_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 13s 648ms/step - loss: 0.0243 - test_accuracy: 0.9906 - val_loss: 0.0029 - val_test_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 8s 423ms/step - loss: 0.0041 - test_accuracy: 1.0000 - val_loss: 8.4479e-04 - val_test_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 8s 393ms/step - loss: 0.0016 - test_accuracy: 1.0000 - val_loss: 4.2062e-04 - val_test_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 9s 435ms/step - loss: 5.5864e-04 - test_accuracy: 1.0000 - val_loss: 3.2886e-04 - val_test_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 8s 399ms/step - loss: 0.0017 - test_accuracy: 0.9990 - val_loss: 3.1939e-04 - val_test_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 13s 645ms/step - loss: 4.7637e-04 - test_accuracy: 1.0000 - val_loss: 3.1703e-04 - val_test_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "bert_model = text_classifier.TextClassifier.create(train_data, validation_data, options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VWyP7oHw8m_K",
        "outputId": "9a85b26b-e942-438e-afe7-834cb81e852e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 2s 77ms/step - loss: 0.3878 - test_accuracy: 0.9071\n",
            "Test loss:0.3878059685230255, Test accuracy:0.9071100950241089\n"
          ]
        }
      ],
      "source": [
        "loss, acc = bert_model.evaluate(validation_data)\n",
        "print(f'Test loss:{loss}, Test accuracy:{acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1dTONm5T8rM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "f901f64b-9cc4-45fd-9b6b-3628378d79fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1024). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a03b1eda4529>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquantization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuantizationConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe_model_maker/python/text/text_classifier/text_classifier.py\u001b[0m in \u001b[0;36mexport_model\u001b[0;34m(self, model_name, quantization_config)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_metadata_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mtflite_model_with_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mmodel_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_with_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtflite_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe_model_maker/python/text/text_classifier/text_classifier.py\u001b[0m in \u001b[0;36m_get_metadata_writer\u001b[0;34m(self, tflite_model, vocab_filepath)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_metadata_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtflite_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_filepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m     return text_classifier_writer.MetadataWriter.create_for_bert_model(\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mmodel_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/tasks/python/metadata/metadata_writers/text_classifier.py\u001b[0m in \u001b[0;36mcreate_for_bert_model\u001b[0;34m(cls, model_buffer, tokenizer, labels, ids_name, mask_name, segment_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadataWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_general_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MODEL_DESCRIPTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bert_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_classification_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/tasks/python/metadata/metadata_writers/metadata_writer.py\u001b[0m in \u001b[0;36madd_bert_text_input\u001b[0;34m(self, tokenizer, ids_name, mask_name, segment_name)\u001b[0m\n\u001b[1;32m    566\u001b[0m       raise ValueError(\n\u001b[1;32m    567\u001b[0m           f'The type of tokenizer, {type(tokenizer)}, is unsupported')\n\u001b[0;32m--> 568\u001b[0;31m     bert_input_md = metadata_info.BertInputTensorsMd(\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mids_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/tasks/python/metadata/metadata_writers/metadata_info.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_buffer, ids_name, mask_name, segment_name, tokenizer_md)\u001b[0m\n\u001b[1;32m    683\u001b[0m     if collections.Counter(tflite_input_names) != collections.Counter(\n\u001b[1;32m    684\u001b[0m         input_names):\n\u001b[0;32m--> 685\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m    686\u001b[0m           \u001b[0;34mf\"The input tensor names ({input_names}) do not match the tensor \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m           f\"names read from the model ({tflite_input_names}).\")\n",
            "\u001b[0;31mValueError\u001b[0m: The input tensor names (['serving_default_input_1:0', 'serving_default_input_3:0', 'serving_default_input_2:0']) do not match the tensor names read from the model (['serving_default_input_6:0', 'serving_default_input_4:0', 'serving_default_input_5:0'])."
          ]
        }
      ],
      "source": [
        "from mediapipe_model_maker import quantization\n",
        "quantization_config = quantization.QuantizationConfig.for_dynamic()\n",
        "bert_model.export_model(quantization_config=quantization_config)\n",
        "bert_model.export_labels(export_dir=options.hparams.export_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}